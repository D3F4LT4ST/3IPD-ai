{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5b54ee1-6af7-4bb8-96b5-fdca28ab3342",
   "metadata": {},
   "source": [
    "## 3IPD LLM Strategy Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5035725d-da56-430a-bc13-f4aed5b22ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.abspath(\"\"), os.pardir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc5fef2-6e4f-4ca9-92aa-5574bcf0030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from эipdai import IPDGame, Actions\n",
    "from эipdai.strategies import *\n",
    "from эipdai.tournament import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83680896-8349-4681-adca-4a50503ea18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_opponent_actions(obs):\n",
    "    actions = obs.T[-1][1:]\n",
    "    if any(actions < 0):\n",
    "        return None\n",
    "    else:\n",
    "        return list(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc93dfa-c37c-4387-9c9d-a34c3f6808c9",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "* Minimum background info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5e3fc1-dc79-4538-a7ad-c20039854892",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = '''\n",
    "Three-player iterated prisoner's dilemma is a game involving three players who repeatedly choose whether to cooperate or betray each other. Here's how it works:\n",
    "\n",
    "Players: You, Player A, and Player B.\n",
    "Actions: In each round, you have two choices: cooperate (0) or defect (1).\n",
    "Rewards: The outcomes depend on everyone's choices:\n",
    "* If all three players cooperate, they all receive a reward of 6.\n",
    "* If one player cooperates while the other two defect, the defectors get a reward of 5 and the cooperator gets a payoff of 0.\n",
    "* If two players cooperate while the third defects, the two cooperators receive a reward of 3, and the defector gets a high reward of 8.\n",
    "* If all three players defect on each other, they all receive a low payoff of 2.\n",
    "\n",
    "Your goal is to maximize your return, i.e. the sum of the rewards you receive.\n",
    "I will give you an observation, reward and the return so far, formatted as:\n",
    "\n",
    "Observation: <observation>\n",
    "Reward: <reward>\n",
    "Return: <return>\n",
    "\n",
    "where <observation> will contain the actions of opponents from the last round, or None if the game has just started. \n",
    "\n",
    "You will respond with an action, formatted as:\n",
    "\n",
    "Action: <action>\n",
    "\n",
    "where you replace <action> with your actual action, either 0 or 1.\n",
    "Do nothing else but return the action.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aef8fc7-080e-44fc-ac19-1d587dae567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_agent = LLMStrategy(\n",
    "    ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY']),\n",
    "    instructions,\n",
    "    obs_preprocessor=last_opponent_actions,\n",
    "    name='LLM'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e56e8-7d22-431e-911d-f19e452303ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Run 1\n",
    "* 50 rounds\n",
    "* Naive opponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea22d842-029b-4918-8962-eb79672416ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = IPDGame(min_rounds=50, max_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d7689ba-8237-4d42-884b-06b8643de898",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = [llm_agent, Naive(), Naive()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbecf692-0ecf-4d9a-82f1-433238527220",
   "metadata": {},
   "outputs": [],
   "source": [
    "for player in players:\n",
    "    player.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c40ee53-f756-4465-833b-f3276b68ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████▍| 49/50 [01:40<00:02,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "observations, infos = environment.reset()\n",
    "rewards = {agent_id: None for agent_id in environment.possible_agents}\n",
    "returns = {agent_id: 0 for agent_id in environment.possible_agents}\n",
    "\n",
    "for i in tqdm.tqdm(range(50)):\n",
    "    actions = {\n",
    "        agent_id : players[i].play(observations[agent_id], rewards[agent_id]) \n",
    "        for i, agent_id in enumerate(environment.possible_agents)\n",
    "    }\n",
    "\n",
    "    observations, rewards, terminations, trunctations, infos = environment.step(actions)\n",
    "    \n",
    "    for agent_id in environment.possible_agents:\n",
    "        returns[agent_id] += rewards[agent_id]\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c6acd0a-e300-4154-bfca-4214c6300795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'player_0': True, 'player_1': True, 'player_2': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d5d9f4a-156c-4a5c-8a8e-fa851284afea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'player_0': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]]),\n",
       " 'player_1': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]]),\n",
       " 'player_2': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "964f133e-68ce-4f4e-9abc-d2f0e98e4889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'player_0': 300, 'player_1': 300, 'player_2': 300}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166e5028-1489-48ed-ac22-c9e759f900a1",
   "metadata": {},
   "source": [
    "#### Run 2\n",
    "* 50 rounds\n",
    "* Defector and Naive opponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdc91ee9-33c4-42d1-8fe3-897734ea5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = IPDGame(min_rounds=50, max_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1e51d56-599c-41a7-8568-6b7c8a695eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = [llm_agent, Naive(), Defector()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e0732c5-75d9-489c-8c6f-a4911b8756a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for player in players:\n",
    "    player.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6b1f4dc-cc5a-4eec-8430-bd52fe79141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 50/50 [01:35<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "observations, infos = environment.reset()\n",
    "rewards = {agent_id: None for agent_id in environment.possible_agents}\n",
    "returns = {agent_id: 0 for agent_id in environment.possible_agents}\n",
    "\n",
    "for i in tqdm.tqdm(range(50)):\n",
    "    actions = {\n",
    "        agent_id : players[i].play(observations[agent_id], rewards[agent_id]) \n",
    "        for i, agent_id in enumerate(environment.possible_agents)\n",
    "    }\n",
    "\n",
    "    observations, rewards, terminations, trunctations, infos = environment.step(actions)\n",
    "    \n",
    "    for agent_id in environment.possible_agents:\n",
    "        returns[agent_id] += rewards[agent_id]\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74ba7a8d-6f39-46d3-9807-0fdc1504687c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"\\nThree-player iterated prisoner's dilemma is a game involving three players who repeatedly choose whether to cooperate or betray each other. Here's how it works:\\n\\nPlayers: You, Player A, and Player B.\\nActions: In each round, you have two choices: cooperate (0) or defect (1).\\nRewards: The outcomes depend on everyone's choices:\\n* If all three players cooperate, they all receive a reward of 6.\\n* If one player cooperates while the other two defect, the defectors get a reward of 5 and the cooperator gets a payoff of 0.\\n* If two players cooperate while the third defects, the two cooperators receive a reward of 3, and the defector gets a high reward of 8.\\n* If all three players defect on each other, they all receive a low payoff of 2.\\n\\nYour goal is to maximize your return, i.e. the sum of the rewards you receive.\\nI will give you an observation, reward and the return so far, formatted as:\\n\\nObservation: <observation>\\nReward: <reward>\\nReturn: <return>\\n\\nwhere <observation> will contain the actions of opponents from the last round, or None if the game has just started. \\n\\nYou will respond with an action, formatted as:\\n\\nAction: <action>\\n\\nwhere you replace <action> with your actual action, either 0 or 1.\\nDo nothing else but return the action.\\n\"),\n",
       " HumanMessage(content='\\n        Observation: None\\n        Reward: None\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 3\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 6\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 9\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 12\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 15\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 18\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 21\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 24\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 27\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 30\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 33\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 36\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 39\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 42\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 45\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 48\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 51\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 54\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 57\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 60\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 63\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 66\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 69\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 72\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 75\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 78\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 81\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 84\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 87\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 90\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 93\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 96\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 99\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 102\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 105\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 108\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 111\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 114\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 117\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 120\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 123\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 126\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 129\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 132\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 135\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 138\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 141\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 144\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [0, 1]\\n        Reward: 3\\n        Return: 147\\n        '),\n",
       " AIMessage(content='Action: 0')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_agent._message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e20ed13-fcc2-4e0b-8d89-d19045482bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations['player_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4beefcc8-c8c9-472c-abfe-27769ad02305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'player_0': 150, 'player_1': 150, 'player_2': 400}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14b952-d96e-4cf3-be07-729c65c670cd",
   "metadata": {},
   "source": [
    "#### Run 3\n",
    "* 50 rounds\n",
    "* Defector opponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d2473be-ad38-4634-8ff9-ce712b1fb9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = IPDGame(min_rounds=50, max_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42ca628a-31d0-4955-91e8-5c16dfc06974",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = [llm_agent, Defector(), Defector()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed4bb947-082c-4f78-976f-561237cd3103",
   "metadata": {},
   "outputs": [],
   "source": [
    "for player in players:\n",
    "    player.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3f376e1-f33e-4b21-bccc-dd489e3d980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 50/50 [01:32<00:00,  1.85s/it]\n"
     ]
    }
   ],
   "source": [
    "observations, infos = environment.reset()\n",
    "rewards = {agent_id: None for agent_id in environment.possible_agents}\n",
    "returns = {agent_id: 0 for agent_id in environment.possible_agents}\n",
    "\n",
    "for i in tqdm.tqdm(range(50)):\n",
    "    actions = {\n",
    "        agent_id : players[i].play(observations[agent_id], rewards[agent_id]) \n",
    "        for i, agent_id in enumerate(environment.possible_agents)\n",
    "    }\n",
    "\n",
    "    observations, rewards, terminations, trunctations, infos = environment.step(actions)\n",
    "    \n",
    "    for agent_id in environment.possible_agents:\n",
    "        returns[agent_id] += rewards[agent_id]\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da9b0e4b-89c4-4a07-8450-a831572782e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations['player_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c25a5033-fbcb-4978-848b-e06af55c0ea8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"\\nThree-player iterated prisoner's dilemma is a game involving three players who repeatedly choose whether to cooperate or betray each other. Here's how it works:\\n\\nPlayers: You, Player A, and Player B.\\nActions: In each round, you have two choices: cooperate (0) or defect (1).\\nRewards: The outcomes depend on everyone's choices:\\n* If all three players cooperate, they all receive a reward of 6.\\n* If one player cooperates while the other two defect, the defectors get a reward of 5 and the cooperator gets a payoff of 0.\\n* If two players cooperate while the third defects, the two cooperators receive a reward of 3, and the defector gets a high reward of 8.\\n* If all three players defect on each other, they all receive a low payoff of 2.\\n\\nYour goal is to maximize your return, i.e. the sum of the rewards you receive.\\nI will give you an observation, reward and the return so far, formatted as:\\n\\nObservation: <observation>\\nReward: <reward>\\nReturn: <return>\\n\\nwhere <observation> will contain the actions of opponents from the last round, or None if the game has just started. \\n\\nYou will respond with an action, formatted as:\\n\\nAction: <action>\\n\\nwhere you replace <action> with your actual action, either 0 or 1.\\nDo nothing else but return the action.\\n\"),\n",
       " HumanMessage(content='\\n        Observation: None\\n        Reward: None\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0'),\n",
       " HumanMessage(content='\\n        Observation: [1, 1]\\n        Reward: 0\\n        Return: 0\\n        '),\n",
       " AIMessage(content='Action: 0')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_agent._message_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ad6a2-4dab-4ca7-b945-a0bf70eb9f08",
   "metadata": {},
   "source": [
    "#### Run 4\n",
    "* 50 rounds\n",
    "* Defector and ToughT4T opponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fb310f9-255f-4094-bd3f-47448103d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = IPDGame(min_rounds=50, max_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba5bc7b7-4ba3-4a8b-8eb8-d054350bb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = [llm_agent, Defector(), ToughT4T()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "262907fd-f332-4804-9f1e-57da7c6750cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for player in players:\n",
    "    player.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5a29ce9-832f-49f3-bcf6-0f49ce51b1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 50/50 [01:33<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "observations, infos = environment.reset()\n",
    "rewards = {agent_id: None for agent_id in environment.possible_agents}\n",
    "returns = {agent_id: 0 for agent_id in environment.possible_agents}\n",
    "\n",
    "for i in tqdm.tqdm(range(50)):\n",
    "    actions = {\n",
    "        agent_id : players[i].play(observations[agent_id], rewards[agent_id]) \n",
    "        for i, agent_id in enumerate(environment.possible_agents)\n",
    "    }\n",
    "\n",
    "    observations, rewards, terminations, trunctations, infos = environment.step(actions)\n",
    "    \n",
    "    for agent_id in environment.possible_agents:\n",
    "        returns[agent_id] += rewards[agent_id]\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "680d8301-9f95-4f79-8f8f-bd673accc10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations['player_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60781b11-1b76-4863-b884-90e72e2d615c",
   "metadata": {},
   "source": [
    "#### Run 5\n",
    "* 50 rounds\n",
    "* Grofman and DecayingT4T opponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78de86f7-d7d8-49a4-bf2b-0f0bfcbe74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = IPDGame(min_rounds=50, max_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60eabc94-b04a-4d6f-a8ef-5b6311f37ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = [llm_agent, Grofman(), DecayingT4T()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b4119ef-d81b-4480-9f07-4f9fa0281727",
   "metadata": {},
   "outputs": [],
   "source": [
    "for player in players:\n",
    "    player.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4b2e92-fbdf-4052-b74b-3fd142dd3f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 50/50 [01:33<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "observations, infos = environment.reset()\n",
    "rewards = {agent_id: None for agent_id in environment.possible_agents}\n",
    "returns = {agent_id: 0 for agent_id in environment.possible_agents}\n",
    "\n",
    "for i in tqdm.tqdm(range(50)):\n",
    "    actions = {\n",
    "        agent_id : players[i].play(observations[agent_id], rewards[agent_id]) \n",
    "        for i, agent_id in enumerate(environment.possible_agents)\n",
    "    }\n",
    "\n",
    "    observations, rewards, terminations, trunctations, infos = environment.step(actions)\n",
    "    \n",
    "    for agent_id in environment.possible_agents:\n",
    "        returns[agent_id] += rewards[agent_id]\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "216bbec1-f588-42cd-b364-c0572da9240c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "        0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations['player_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc658b8f-884a-4c9b-9846-4e6011a87e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'player_0': 145, 'player_1': 205, 'player_2': 230}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
